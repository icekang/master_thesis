@string{SP="IEEE Security and Privacy Magazine"}
@string{CODASPY="ACM Conference on Data and Application Security and Privacy"}
@string{ATC="Usenix Annual Technical Conference"}
@string{CSUR="ACM Computing Surveys"}
@string{RTSS="Real-Time Systems Symposium"}
@string{arXiv="arXiv Technical Report"}
@string{LangSec="Language-theoretic Security IEEE Security and Privacy Workshop"}
@string{CCS="ACM Conference on Computer and Communication Security"}
@string{IOTSP="Workshop on the Internet of Things Security and Privacy"}
@string{NDSS="Network and Distributed System Security Symposium"}
@string{ISPASS="International Symposium on Performance Analysis of Systems and Software"}
@string{CCC="Chaos Communication Congress"}
@string{NSPW="New Security Paradigms Workshop"}
@string{BHEU="BlackHat Europe"}
@string{TR="Technical Report"}
@string{PLDI="ACM International Conference on Programming Language Design and Implementation"}
@string{EuroSP="IEEE European Symposium on Security and Privacy"}
@string{SS3P="Open Textbook"}
@string{DIMVA="Conference on Detection of Intrusions and Malware and Vulnerability Assessment"}
@string{ISMM="ACM SIGPLAN International Symposium on Memory Management"}
@string{ESSoS="Int'l. Symp. on Eng. Secure Software and Systems"}
@string{SEC="Usenix Security Symposium"}
@string{IMC="ACM Internet Measurement Conference"}
@string{TSE="IEEE Transactions on Software Engineering"}
@string{CC="International Conference on Compiler Construction"}
@string{STM="International Workshop on Security and Trust Management"}
@string{ArmsRace="The Continuing Arms Race"}
@string{TRB="Transportation Research Board"}
@string{FEAST="Forming an Ecosystem Around Software Transformation"}
@string{DSN="IEEE/IFIP International Conference on Dependable Systems and Networks"}
@string{SyScan360="Symposium on Security for Asia Network + 360"}
@string{BalCCon="Balkan Computer Congress"}
@string{DSAL="AOSD workshop on Domain-Specific Aspect Languages"}
@string{ESORICS="European Symposium on Research in Computer Security"}
@string{WOOT="Usenix Workshop on Offensive Technologies"}
@string{TIFS="IEEE Transactions on Information Forensics and Security"}
@string{HotSWUp="Usenix Workshop on Hot Topics in Software Upgrades"}
@string{AsiaCCS="ACM Symp. on InformAtion, Computer and Communications Security"}
@string{AMAS-BT="Workshop on Architectural and Microarchitectural Support for Binary Translation"}
@string{PPREW="Program Protection and Reverse Engineering Workshop"}
@string{SYSTOR="ACM International Systems and Storage Conference"}
@string{VEE="ACM International Conference on Virtual Execution Environments"}
@string{OSDI="Usenix Symposium on Operating Systems Design and Implementation"}
@string{Oakland="IEEE International Symposium on Security and Privacy"}
@string{PST="IEEE Conference on Privacy, Security, and Trust"}

@inproceedings{Assran2023,
  title     = {Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture},
  url       = {http://dx.doi.org/10.1109/CVPR52729.2023.01499},
  doi       = {10.1109/cvpr52729.2023.01499},
  booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {Assran,  Mahmoud and Duval,  Quentin and Misra,  Ishan and Bojanowski,  Piotr and Vincent,  Pascal and Rabbat,  Michael and LeCun,  Yann and Ballas,  Nicolas},
  year      = {2023},
  month     = jun
}

@inproceedings{Bao2022beit,
  title     = {{BE}iT: {BERT} Pre-Training of Image Transformers},
  author    = {Hangbo Bao and Li Dong and Songhao Piao and Furu Wei},
  booktitle = {International Conference on Learning Representations},
  year      = {2022},
  url       = {https://openreview.net/forum?id=p-BhZSz59o4}
}

@inproceedings{Caron2018,
  author    = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  title     = {Deep Clustering for Unsupervised Learning of Visual Features},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  month     = {September},
  year      = {2018}
}
@article{Chen2019,
  title     = {Self-supervised learning for medical image analysis using image context restoration},
  volume    = {58},
  issn      = {1361-8415},
  url       = {http://dx.doi.org/10.1016/j.media.2019.101539},
  doi       = {10.1016/j.media.2019.101539},
  journal   = {Medical Image Analysis},
  publisher = {Elsevier BV},
  author    = {Chen,  Liang and Bentley,  Paul and Mori,  Kensaku and Misawa,  Kazunari and Fujiwara,  Michitaka and Rueckert,  Daniel},
  year      = {2019},
  month     = dec,
  pages     = {101539}
}
@inproceedings{Chen2020,
  author    = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
  title     = {Big self-supervised models are strong semi-supervised learners},
  year      = {2020},
  isbn      = {9781713829546},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {One paradigm for learning from few labeled examples while making best use of a large amount of unlabeled data is unsupervised pretraining followed by supervised fine-tuning. Although this paradigm uses unlabeled data in a task-agnostic way, in contrast to common approaches to semi-supervised learning for computer vision, we show that it is surprisingly effective for semi-supervised learning on ImageNet. A key ingredient of our approach is the use of big (deep and wide) networks during pretraining and fine-tuning. We find that, the fewer the labels, the more this approach (task-agnostic use of unlabeled data) benefits from a bigger network. After fine-tuning, the big network can be further improved and distilled into a much smaller one with little loss in classification accuracy by using the unlabeled examples for a second time, but in a task-specific way. The proposed semi-supervised learning algorithm can be summarized in three steps: unsupervised pretraining of a big ResNet model using SimCLRv2, supervised fine-tuning on a few labeled examples, and distillation with unlabeled examples for refining and transferring the task-specific knowledge. This procedure achieves 73.9\% ImageNet top-1 accuracy with just 1\% of the labels (≤13 labeled images per class) using ResNet-50, a 10 x improvement in label efficiency over the previous state-of-the-art. With 10\% of labels, ResNet-50 trained with our method achieves 77.5\% top-1 accuracy, outperforming standard supervised training with all of the labels.},
  booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
  articleno = {1865},
  numpages  = {13},
  location  = {Vancouver, BC, Canada},
  series    = {NIPS '20}
}
@inproceedings{Chen2020Simple,
  author    = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  title     = {A simple framework for contrastive learning of visual representations},
  year      = {2020},
  publisher = {JMLR.org},
  abstract  = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by Sim-CLR achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming AlexNet with 100\texttimes{} fewer labels.},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  articleno = {149},
  numpages  = {11},
  series    = {ICML'20}
}
@inproceedings{Devlin2019,
  url       = {http://dx.doi.org/10.18653/v1/N19-1423},
  doi       = {10.18653/v1/n19-1423},
  booktitle = {Proceedings of the 2019 Conference of the North},
  publisher = {Association for Computational Linguistics},
  author    = {Devlin,  Jacob and Chang,  Ming-Wei and Lee,  Kenton and Toutanova,  Kristina},
  year      = {2019}
}
@article{Dosovitskiy2020vit,
  title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal = {ICLR},
  year    = {2021}
}

@inbook{Dufumier2021,
  title     = {Contrastive Learning with Continuous Proxy Meta-data for 3D MRI Classification},
  isbn      = {9783030871963},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-030-87196-3_6},
  doi       = {10.1007/978-3-030-87196-3_6},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  author    = {Dufumier,  Benoit and Gori,  Pietro and Victor,  Julie and Grigis,  Antoine and Wessa,  Michele and Brambilla,  Paolo and Favre,  Pauline and Polosan,  Mircea and McDonald,  Colm and Piguet,  Camille Marie and Phillips,  Mary and Eyler,  Lisa and Duchesnay,  Edouard},
  year      = {2021},
  pages     = {58–68}
}

@inproceedings{Hager2023,
  author    = {Hager, Paul and Menten, Martin J. and Rueckert, Daniel},
  booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  doi       = {10.1109/cvpr52729.2023.02291},
  month     = {June},
  publisher = {IEEE},
  title     = {Best of Both Worlds: Multimodal Contrastive Learning with Tabular and Imaging Data},
  url       = {http://dx.doi.org/10.1109/CVPR52729.2023.02291},
  year      = {2023}
}

@article{Haghighi2021,
  title     = {Transferable Visual Words: Exploiting the Semantics of Anatomical Patterns for Self-Supervised Learning},
  volume    = {40},
  issn      = {1558-254X},
  url       = {http://dx.doi.org/10.1109/TMI.2021.3060634},
  doi       = {10.1109/tmi.2021.3060634},
  number    = {10},
  journal   = {IEEE Transactions on Medical Imaging},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Haghighi,  Fatemeh and Taher,  Mohammad Reza Hosseinzadeh and Zhou,  Zongwei and Gotway,  Michael B. and Liang,  Jianming},
  year      = {2021},
  month     = oct,
  pages     = {2857–2868}
}
@article{Haghighi2024,
  title     = {Self-supervised learning for medical image analysis: Discriminative,  restorative,  or adversarial?},
  volume    = {94},
  issn      = {1361-8415},
  url       = {http://dx.doi.org/10.1016/j.media.2024.103086},
  doi       = {10.1016/j.media.2024.103086},
  journal   = {Medical Image Analysis},
  publisher = {Elsevier BV},
  author    = {Haghighi,  Fatemeh and Hosseinzadeh Taher,  Mohammad Reza and Gotway,  Michael B. and Liang,  Jianming},
  year      = {2024},
  month     = may,
  pages     = {103086}
}

@inproceedings{He2016,
  title     = {Deep Residual Learning for Image Recognition},
  url       = {http://dx.doi.org/10.1109/CVPR.2016.90},
  doi       = {10.1109/cvpr.2016.90},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {He,  Kaiming and Zhang,  Xiangyu and Ren,  Shaoqing and Sun,  Jian},
  year      = {2016},
  month     = jun
}

@inproceedings{He2020,
  title     = {Momentum Contrast for Unsupervised Visual Representation Learning},
  url       = {http://dx.doi.org/10.1109/CVPR42600.2020.00975},
  doi       = {10.1109/cvpr42600.2020.00975},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {He,  Kaiming and Fan,  Haoqi and Wu,  Yuxin and Xie,  Saining and Girshick,  Ross},
  year      = {2020},
  month     = jun
}

@inproceedings{He2022,
  title     = {Masked Autoencoders Are Scalable Vision Learners},
  url       = {http://dx.doi.org/10.1109/CVPR52688.2022.01553},
  doi       = {10.1109/cvpr52688.2022.01553},
  booktitle = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {He,  Kaiming and Chen,  Xinlei and Xie,  Saining and Li,  Yanghao and Dollar,  Piotr and Girshick,  Ross},
  year      = {2022},
  month     = jun
}

@article{He2022Intra,
  title     = {Intra- and Inter-Slice Contrastive Learning for Point Supervised OCT Fluid Segmentation},
  volume    = {31},
  issn      = {1941-0042},
  url       = {http://dx.doi.org/10.1109/TIP.2022.3148814},
  doi       = {10.1109/tip.2022.3148814},
  journal   = {IEEE Transactions on Image Processing},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {He,  Xingxin and Fang,  Leyuan and Tan,  Mingkui and Chen,  Xiangdong},
  year      = {2022},
  pages     = {1870–1881}
}

@article{Hinton2006,
  title     = {Reducing the Dimensionality of Data with Neural Networks},
  volume    = {313},
  issn      = {1095-9203},
  url       = {http://dx.doi.org/10.1126/science.1127647},
  doi       = {10.1126/science.1127647},
  number    = {5786},
  journal   = {Science},
  publisher = {American Association for the Advancement of Science (AAAS)},
  author    = {Hinton,  G. E. and Salakhutdinov,  R. R.},
  year      = {2006},
  month     = jul,
  pages     = {504–507}
}

@article{Jaiswal2020,
  title     = {A Survey on Contrastive Self-Supervised Learning},
  volume    = {9},
  issn      = {2227-7080},
  url       = {http://dx.doi.org/10.3390/technologies9010002},
  doi       = {10.3390/technologies9010002},
  number    = {1},
  journal   = {Technologies},
  publisher = {MDPI AG},
  author    = {Jaiswal,  Ashish and Babu,  Ashwin Ramesh and Zadeh,  Mohammad Zaki and Banerjee,  Debapriya and Makedon,  Fillia},
  year      = {2020},
  month     = dec,
  pages     = {2}
}

@misc{Kingma2013,
  doi       = {10.48550/ARXIV.1312.6114},
  url       = {https://arxiv.org/abs/1312.6114},
  author    = {Kingma,  Diederik P and Welling,  Max},
  keywords  = {Machine Learning (stat.ML),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title     = {Auto-Encoding Variational Bayes},
  publisher = {arXiv},
  year      = {2013},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@inproceedings{Larsson2017,
  title     = {Colorization as a Proxy Task for Visual Understanding},
  url       = {http://dx.doi.org/10.1109/CVPR.2017.96},
  doi       = {10.1109/cvpr.2017.96},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {Larsson,  Gustav and Maire,  Michael and Shakhnarovich,  Gregory},
  year      = {2017},
  month     = jul
}

@inbook{Noroozi2016,
  title     = {Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles},
  isbn      = {9783319464664},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-319-46466-4_5},
  doi       = {10.1007/978-3-319-46466-4_5},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  author    = {Noroozi,  Mehdi and Favaro,  Paolo},
  year      = {2016},
  pages     = {69–84}
}

@article{Oquab2024dinov,
  title   = {{DINO}v2: Learning Robust Visual Features without Supervision},
  author  = {Maxime Oquab and Timoth{\'e}e Darcet and Th{\'e}o Moutakanni and Huy V. Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel HAZIZA and Francisco Massa and Alaaeldin El-Nouby and Mido Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Herve Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
  journal = {Transactions on Machine Learning Research},
  issn    = {2835-8856},
  year    = {2024},
  url     = {https://openreview.net/forum?id=a68SUt6zFt},
  note    = {}
}

@inproceedings{Pathak2016,
  title     = {Context Encoders: Feature Learning by Inpainting},
  url       = {http://dx.doi.org/10.1109/CVPR.2016.278},
  doi       = {10.1109/cvpr.2016.278},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  author    = {Pathak,  Deepak and Krahenbuhl,  Philipp and Donahue,  Jeff and Darrell,  Trevor and Efros,  Alexei A.},
  year      = {2016},
  month     = jun
}

@inproceedings{Ronneberger2015,
  author    = {Ronneberger, Olaf
               and Fischer, Philipp
               and Brox, Thomas},
  editor    = {Navab, Nassir
               and Hornegger, Joachim
               and Wells, William M.
               and Frangi, Alejandro F.},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
  year      = {2015},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {234--241},
  abstract  = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  isbn      = {978-3-319-24574-4}
}

@article{Russakovsky2015,
  title     = {ImageNet Large Scale Visual Recognition Challenge},
  volume    = {115},
  issn      = {1573-1405},
  url       = {http://dx.doi.org/10.1007/s11263-015-0816-y},
  doi       = {10.1007/s11263-015-0816-y},
  number    = {3},
  journal   = {International Journal of Computer Vision},
  publisher = {Springer Science and Business Media LLC},
  author    = {Russakovsky,  Olga and Deng,  Jia and Su,  Hao and Krause,  Jonathan and Satheesh,  Sanjeev and Ma,  Sean and Huang,  Zhiheng and Karpathy,  Andrej and Khosla,  Aditya and Bernstein,  Michael and Berg,  Alexander C. and Fei-Fei,  Li},
  year      = {2015},
  month     = apr,
  pages     = {211–252}
}

@article{Song2022,
  title     = {COVID-19 Infection Segmentation and Severity Assessment Using a Self-Supervised Learning Approach},
  volume    = {12},
  issn      = {2075-4418},
  url       = {http://dx.doi.org/10.3390/diagnostics12081805},
  doi       = {10.3390/diagnostics12081805},
  number    = {8},
  journal   = {Diagnostics},
  publisher = {MDPI AG},
  author    = {Song,  Yao and Liu,  Jun and Liu,  Xinghua and Tang,  Jinshan},
  year      = {2022},
  month     = jul,
  pages     = {1805}
}

@inproceedings{Vincent2008,
  series     = {ICML ’08},
  title      = {Extracting and composing robust features with denoising autoencoders},
  url        = {http://dx.doi.org/10.1145/1390156.1390294},
  doi        = {10.1145/1390156.1390294},
  booktitle  = {Proceedings of the 25th international conference on Machine learning - ICML ’08},
  publisher  = {ACM Press},
  author     = {Vincent,  Pascal and Larochelle,  Hugo and Bengio,  Yoshua and Manzagol,  Pierre-Antoine},
  year       = {2008},
  collection = {ICML ’08}
}

@article{Vincent2010,
  author     = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  title      = {Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion},
  year       = {2010},
  issue_date = {3/1/2010},
  publisher  = {JMLR.org},
  volume     = {11},
  issn       = {1532-4435},
  abstract   = {We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.},
  journal    = {J. Mach. Learn. Res.},
  month      = {dec},
  pages      = {3371–3408},
  numpages   = {38}
}

@article{Zhang2021,
  title     = {Twin self-supervision based semi-supervised learning (TS-SSL): Retinal anomaly classification in SD-OCT images},
  volume    = {462},
  issn      = {0925-2312},
  url       = {http://dx.doi.org/10.1016/j.neucom.2021.08.051},
  doi       = {10.1016/j.neucom.2021.08.051},
  journal   = {Neurocomputing},
  publisher = {Elsevier BV},
  author    = {Zhang,  Yuhan and Li,  Mingchao and Ji,  Zexuan and Fan,  Wen and Yuan,  Songtao and Liu,  Qinghuai and Chen,  Qiang},
  year      = {2021},
  month     = oct,
  pages     = {491–505}
}

@article{Zhou2018,
  title     = {Semantic Understanding of Scenes Through the ADE20K Dataset},
  volume    = {127},
  issn      = {1573-1405},
  url       = {http://dx.doi.org/10.1007/s11263-018-1140-0},
  doi       = {10.1007/s11263-018-1140-0},
  number    = {3},
  journal   = {International Journal of Computer Vision},
  publisher = {Springer Science and Business Media LLC},
  author    = {Zhou,  Bolei and Zhao,  Hang and Puig,  Xavier and Xiao,  Tete and Fidler,  Sanja and Barriuso,  Adela and Torralba,  Antonio},
  year      = {2018},
  month     = dec,
  pages     = {302–321}
}

@article{Zhou2020,
  title     = {UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation},
  volume    = {39},
  issn      = {1558-254X},
  url       = {http://dx.doi.org/10.1109/TMI.2019.2959609},
  doi       = {10.1109/tmi.2019.2959609},
  number    = {6},
  journal   = {IEEE Transactions on Medical Imaging},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Zhou,  Zongwei and Siddiquee,  Md Mahfuzur Rahman and Tajbakhsh,  Nima and Liang,  Jianming},
  year      = {2020},
  month     = jun,
  pages     = {1856–1867}
}

@article{Zhou2021,
  title     = {Models Genesis},
  volume    = {67},
  issn      = {1361-8415},
  url       = {http://dx.doi.org/10.1016/j.media.2020.101840},
  doi       = {10.1016/j.media.2020.101840},
  journal   = {Medical Image Analysis},
  publisher = {Elsevier BV},
  author    = {Zhou,  Zongwei and Sodha,  Vatsal and Pang,  Jiaxuan and Gotway,  Michael B. and Liang,  Jianming},
  year      = {2021},
  month     = jan,
  pages     = {101840}
}

@inbook{Zhuang2019,
  title     = {Self-supervised Feature Learning for 3D Medical Images by Playing a Rubik’s Cube},
  isbn      = {9783030322519},
  issn      = {1611-3349},
  url       = {http://dx.doi.org/10.1007/978-3-030-32251-9_46},
  doi       = {10.1007/978-3-030-32251-9_46},
  booktitle = {Medical Image Computing and Computer Assisted Intervention – MICCAI 2019},
  publisher = {Springer International Publishing},
  author    = {Zhuang,  Xinrui and Li,  Yuexiang and Hu,  Yifan and Ma,  Kai and Yang,  Yujiu and Zheng,  Yefeng},
  year      = {2019},
  pages     = {420–428}
}